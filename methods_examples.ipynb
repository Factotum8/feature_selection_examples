{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example from user [guid](https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tmp = SelectKBest(chi2, k=2)\n",
    "X_new = X_tmp.fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point all feateres: [ 10.81782088   3.7107283  116.31261309  67.0483602 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_tmp = SelectKBest(chi2, k=2).fit(X, y)\n",
    "print(\"Point all feateres: {}\".format(X_tmp.scores_))  # shape without target value 4\n",
    "X_new = X_tmp.fit(X, y)\n",
    "# print(\"K highest scoring features: {}\".format(X_new.transform(X)))\n",
    "# print(\"K highest scoring features: {}\".format(iris.DESCR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие признаки `petal length` и `petal width`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['setosa', 'versicolor', 'virginica']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "data.target[[10, 25, 50]]\n",
    "list(data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Code source: Gaël Varoquaux\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Though the following import is not directly being used, it is required\n",
    "# for 3D projection to work\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "estimators = [('k_means_iris_8', KMeans(n_clusters=8)),\n",
    "              ('k_means_iris_3', KMeans(n_clusters=3)),\n",
    "              ('k_means_iris_bad_init', KMeans(n_clusters=3, n_init=1,\n",
    "                                               init='random'))]\n",
    "\n",
    "fignum = 1\n",
    "titles = ['8 clusters', '3 clusters', '3 clusters, bad initialization']\n",
    "for name, est in estimators:\n",
    "    fig = plt.figure(fignum, figsize=(4, 3))\n",
    "    ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "    est.fit(X)\n",
    "    labels = est.labels_\n",
    "\n",
    "    ax.scatter(X[:, 3], X[:, 0], X[:, 2],\n",
    "               c=labels.astype(np.float), edgecolor='k')\n",
    "\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "    ax.set_xlabel('Petal width')\n",
    "    ax.set_ylabel('Sepal length')\n",
    "    ax.set_zlabel('Petal length')\n",
    "    ax.set_title(titles[fignum - 1])\n",
    "    ax.dist = 12\n",
    "    fignum = fignum + 1\n",
    "\n",
    "# Plot the ground truth\n",
    "fig = plt.figure(fignum, figsize=(4, 3))\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "for name, label in [('Setosa', 0),\n",
    "                    ('Versicolour', 1),\n",
    "                    ('Virginica', 2)]:\n",
    "    ax.text3D(X[y == label, 3].mean(),\n",
    "              X[y == label, 0].mean(),\n",
    "              X[y == label, 2].mean() + 2, name,\n",
    "              horizontalalignment='center',\n",
    "              bbox=dict(alpha=.2, edgecolor='w', facecolor='w'))\n",
    "# Reorder the labels to have colors matching the cluster results\n",
    "y = np.choose(y, [1, 2, 0]).astype(np.float)\n",
    "ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=y, edgecolor='k')\n",
    "\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "ax.set_xlabel('Petal width')\n",
    "ax.set_ylabel('Sepal length')\n",
    "ax.set_zlabel('Petal length')\n",
    "ax.set_title('Ground Truth')\n",
    "ax.dist = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chi-squared test [article](http://datareview.info/article/otbor-priznakov-dlya-mashinnogo-obucheniya-na-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Features       Values\n",
      "0     preg   111.519691\n",
      "1     plas  1411.887041\n",
      "2     pres    17.605373\n",
      "3     skin    53.108040\n",
      "4     test  2175.565273\n",
      "5     mass   127.669343\n",
      "6     pedi     5.392682\n",
      "7      age   181.303689\n",
      "new shape: (768, 4)\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# load data\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "if os.path.exists(\"./data/diabetes.csv\"):\n",
    "    dataframe = pd.read_csv(\"./data/diabetes.csv\", names=names)\n",
    "else:\n",
    "    print(\"Put diabetes.csv in folder 'data'\")\n",
    "    exit(1)\n",
    "    \n",
    "array = dataframe[1:].astype('float64')\n",
    "X = array.iloc[:,0:8]\n",
    "Y = array.iloc[:,8]\n",
    "\n",
    "# feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X, Y)\n",
    "\n",
    "# summarize scores\n",
    "numpy.set_printoptions(precision=3)  # Number of digits of precision for floating point output (8 to 3)\n",
    "print(pd.DataFrame({\"Features\": names[:8], \"Values\": fit.scores_}))\n",
    "features = fit.transform(X)\n",
    "# summarize selected features\n",
    "print(f\"new shape: {features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plas</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>Insulin</td>\n",
       "      <td>BMI</td>\n",
       "      <td>Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>137</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>197</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>189</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>166</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>118</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>103</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>115</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>126</td>\n",
       "      <td>235</td>\n",
       "      <td>39.3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>36.6</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>125</td>\n",
       "      <td>115</td>\n",
       "      <td>31.1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>97</td>\n",
       "      <td>140</td>\n",
       "      <td>23.2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>145</td>\n",
       "      <td>110</td>\n",
       "      <td>22.2</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>99</td>\n",
       "      <td>160</td>\n",
       "      <td>36.6</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>120</td>\n",
       "      <td>150</td>\n",
       "      <td>42.3</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>102</td>\n",
       "      <td>94</td>\n",
       "      <td>30.8</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>109</td>\n",
       "      <td>116</td>\n",
       "      <td>28.5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>153</td>\n",
       "      <td>140</td>\n",
       "      <td>40.6</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>100</td>\n",
       "      <td>105</td>\n",
       "      <td>30</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>81</td>\n",
       "      <td>57</td>\n",
       "      <td>46.3</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>187</td>\n",
       "      <td>200</td>\n",
       "      <td>36.4</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>121</td>\n",
       "      <td>74</td>\n",
       "      <td>39</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>181</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>128</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>101</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>121</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>769 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        plas     test  mass  age\n",
       "0    Glucose  Insulin   BMI  Age\n",
       "1        148        0  33.6   50\n",
       "2         85        0  26.6   31\n",
       "3        183        0  23.3   32\n",
       "4         89       94  28.1   21\n",
       "5        137      168  43.1   33\n",
       "6        116        0  25.6   30\n",
       "7         78       88    31   26\n",
       "8        115        0  35.3   29\n",
       "9        197      543  30.5   53\n",
       "10       125        0     0   54\n",
       "11       110        0  37.6   30\n",
       "12       168        0    38   34\n",
       "13       139        0  27.1   57\n",
       "14       189      846  30.1   59\n",
       "15       166      175  25.8   51\n",
       "16       100        0    30   32\n",
       "17       118      230  45.8   31\n",
       "18       107        0  29.6   31\n",
       "19       103       83  43.3   33\n",
       "20       115       96  34.6   32\n",
       "21       126      235  39.3   27\n",
       "22        99        0  35.4   50\n",
       "23       196        0  39.8   41\n",
       "24       119        0    29   29\n",
       "25       143      146  36.6   51\n",
       "26       125      115  31.1   41\n",
       "27       147        0  39.4   43\n",
       "28        97      140  23.2   22\n",
       "29       145      110  22.2   57\n",
       "..       ...      ...   ...  ...\n",
       "739       99      160  36.6   21\n",
       "740      102        0  39.5   42\n",
       "741      120      150  42.3   48\n",
       "742      102       94  30.8   26\n",
       "743      109      116  28.5   22\n",
       "744      140        0  32.7   45\n",
       "745      153      140  40.6   39\n",
       "746      100      105    30   46\n",
       "747      147        0  49.3   27\n",
       "748       81       57  46.3   32\n",
       "749      187      200  36.4   36\n",
       "750      162        0  24.3   50\n",
       "751      136        0  31.2   22\n",
       "752      121       74    39   28\n",
       "753      108        0    26   25\n",
       "754      181      510  43.3   26\n",
       "755      154        0  32.4   45\n",
       "756      128      110  36.5   37\n",
       "757      137        0    32   39\n",
       "758      123        0  36.3   52\n",
       "759      106        0  37.5   26\n",
       "760      190        0  35.5   66\n",
       "761       88       16  28.4   22\n",
       "762      170        0    44   43\n",
       "763       89        0  22.5   33\n",
       "764      101      180  32.9   63\n",
       "765      122        0  36.8   27\n",
       "766      121      112  26.2   30\n",
       "767      126        0  30.1   47\n",
       "768       93        0  30.4   23\n",
       "\n",
       "[769 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[dataframe.columns[fit.get_support(indices=True)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing features with low variance [User Guide](https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[0, 0, 1], [0, 1, 0], [0, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "sel = VarianceThreshold(threshold=(.95 * (1 - .95)))\n",
    "sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive feature elimination [artical](http://datareview.info/article/otbor-priznakov-dlya-mashinnogo-obucheniya-na-python/)\n",
    "Метод рекурсивного исключения признаков (recursive feature elimination, RFE) реализует следующий алгоритм: модель обучается на исходном наборе признаков и оценивает их значимость, затем исключается один или несколько наименее значимых признаков, модель обучается на оставшихся признаках, и так далее, пока не останется заданное количество лучших признаков. В документации scikit-learn вы можете подробнее прочитать о классе [RFE](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 3\n",
      "Selected Features: [ True False False False False  True  True False]\n",
      "Feature Ranking: [1 2 3 5 6 1 1 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/worker/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/worker/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/worker/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/worker/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/worker/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/worker/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction with RFE\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# load data\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "if os.path.exists(\"./data/diabetes.csv\"):\n",
    "    dataframe = pd.read_csv(\"./data/diabetes.csv\", names=names)\n",
    "else:\n",
    "    print(\"Put diabetes.csv in folder 'data'\")\n",
    "    exit(1)\n",
    "array = dataframe.values\n",
    "    \n",
    "array = dataframe[1:].astype('float64')\n",
    "X = array.iloc[:,0:8]\n",
    "Y = array.iloc[:,8]\n",
    "\n",
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, Y)\n",
    "\n",
    "print(\"Num Features: {}\".format(fit.n_features_))\n",
    "print(\"Selected Features: {}\".format(fit.support_))\n",
    "print(\"Feature Ranking: {}\".format(fit.ranking_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal component analysis [artical](http://datareview.info/article/otbor-priznakov-dlya-mashinnogo-obucheniya-na-python/)\n",
    "Метод главных компонент (principal component analysis, PCA) позволяет уменьшить размерность данных с помощью преобразования на основе линейной алгебры. Пользователь может задать требуемое количество измерений (главных компонент) в результирующих данных.\n",
    "Подробная информация о классе PCA доступна в [документации](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: [0.889 0.062 0.026]\n",
      "[[-7.571e+01 -3.595e+01 -7.261e+00]\n",
      " [-8.236e+01  2.891e+01 -5.497e+00]\n",
      " [-7.463e+01 -6.791e+01  1.946e+01]\n",
      " [ 1.108e+01  3.490e+01 -5.302e-02]\n",
      " [ 8.974e+01 -2.747e+00  2.521e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction with PCA\n",
    "import os\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# load data\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "if os.path.exists(\"./data/diabetes.csv\"):\n",
    "    dataframe = pd.read_csv(\"./data/diabetes.csv\", names=names)\n",
    "else:\n",
    "    print(\"Put diabetes.csv in folder 'data'\")\n",
    "    exit(1)\n",
    "array = dataframe.values\n",
    "\n",
    "array = dataframe[1:].astype('float64')\n",
    "X = array.iloc[:,0:8]\n",
    "Y = array.iloc[:,8]\n",
    "\n",
    "# feature extraction\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "features = fit.transform(X)\n",
    "\n",
    "# summarize components\n",
    "print(f\"Explained Variance: {fit.explained_variance_ratio_}\")\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сжымает в пространство меньшей размерности (TODO не понятно пока что для чего и зачем использовать)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Отбор на основе важности признаков](http://datareview.info/article/otbor-priznakov-dlya-mashinnogo-obucheniya-na-python/)\n",
    "\n",
    "Ансамблевые алгоритмы на основе деревьев решений, такие как случайный лес (random forest), позволяют оценить важность признаков.\n",
    "\n",
    "В представленном ниже примере мы обучаем классификатор ExtraTreesClassifier, чтобы с его помощью определить важность признаков. Подробнее о классе [ExtraTreesClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html) можно узнать из документации scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.115 0.254 0.093 0.084 0.07  0.141 0.117 0.125]\n",
      "  Features    Values\n",
      "0     preg  0.115487\n",
      "1     plas  0.253578\n",
      "2     pres  0.093278\n",
      "3     skin  0.083807\n",
      "4     test  0.070073\n",
      "5     mass  0.141367\n",
      "6     pedi  0.117317\n",
      "7      age  0.125093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/worker/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance with Extra Trees Classifier\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# load data\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "if os.path.exists(\"./data/diabetes.csv\"):\n",
    "    dataframe = pd.read_csv(\"./data/diabetes.csv\", names=names)\n",
    "else:\n",
    "    print(\"Put diabetes.csv in folder 'data'\")\n",
    "    exit(1)\n",
    "array = dataframe.values\n",
    "\n",
    "array = dataframe[1:].astype('float64')\n",
    "X = array.iloc[:,0:8]\n",
    "Y = array.iloc[:,8]\n",
    "\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "\n",
    "# plas, age, mass\n",
    "print(pd.DataFrame({\"Features\": names[:8], \"Values\": model.feature_importances_}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
